{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly project\n",
    "\n",
    "Today you are going to implement the last parts of the algorithm you started on monday. For reference you can see it below.\n",
    "\n",
    "![title](algorithm_3.png)\n",
    "\n",
    "It is a good idea to follow and track the steps in the algorithm in the below implementation. Only take one step at a time.\n",
    "\n",
    "Once you have the algorithm up and running you can try with a larger dataset to see if your algorithm is able to maintain good accurracy over a longer distance. The larger dataset can be found here:\n",
    "[Left images](https://dtudk-my.sharepoint.com/:u:/g/personal/evanb_win_dtu_dk/EQu8kmGBDDROtGJ7IkZB2tQBJrxmgY9t8LVM_JuEi83TYw?e=GiOby4)\n",
    "[Right images](https://dtudk-my.sharepoint.com/:u:/g/personal/evanb_win_dtu_dk/EcKI_zrXTvpMulizidCZm4oBLJcQ_LTV9Zs6oQFF74JTRQ?e=6bgQVw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "image:  0\n[0.00024098] [0.01022083] [0.00016408] [-0.00096574] [2.89571831e-06] [0.00039302]\n[5.551115e-17, 3.330669e-16, -4.440892e-16]\nimage:  1\n[0.01452369] [0.0086075] [0.67819826] [-0.00352797] [0.0041842] [-0.00230283]\n[5.551115e-17, 3.330669e-16, -4.440892e-16]\nimage:  2\n[0.01056032] [0.00553193] [1.3744214] [-0.0053234] [0.00865508] [-0.00102215]\n[-0.04690294, -0.02839928, 0.8586941]\nimage:  3\n[0.02599251] [0.00380252] [2.10589824] [-0.00705085] [0.01434318] [-0.00132975]\n[-0.09374345, -0.05676064, 1.716275]\nimage:  4\n[-0.00032645] [-0.00682603] [2.83534198] [-0.0077967] [0.01892693] [0.00038278]\n[-0.1406429, -0.08515762, 2.574964]\nimage:  5\n[-0.01021558] [0.00078328] [3.5863836] [-0.00940936] [0.02385484] [-0.00047378]\n[-0.1874858, -0.1135202, 3.432648]\nimage:  6\n[-0.03539353] [-0.02101402] [4.3358412] [-0.01027858] [0.02843986] [0.00116786]\n[-0.2343818, -0.141915, 4.291335]\nimage:  7\n[-0.07329654] [-0.0364414] [5.11072144] [-0.01089425] [0.03318906] [0.00381867]\n[-0.2812195, -0.1702743, 5.148987]\nimage:  8\n[-0.10271197] [-0.06877899] [5.8990691] [-0.00812323] [0.03781304] [0.0041964]\n[-0.3281178, -0.1986703, 6.007777]\nimage:  9\n[-0.14289929] [-0.08214381] [6.69587948] [-0.00539963] [0.04194445] [0.00344184]\n[-0.3749547, -0.227029, 6.865477]\nimage:  10\n[-0.18108624] [-0.09501205] [7.50631633] [-0.00268365] [0.04540622] [0.00291323]\n[-0.4218367, -0.2554151, 7.724036]\nimage:  11\n[-0.21914568] [-0.1092833] [8.33187946] [-0.0031207] [0.04853933] [0.00419192]\n[-0.4687329, -0.2838096, 8.582886]\nimage:  12\n[-0.2304442] [-0.10326666] [9.17322264] [-0.00449961] [0.05297854] [0.00360452]\n[-0.5155474, -0.3121547, 9.440275]\nimage:  13\n[-0.27131472] [-0.11546359] [10.00697541] [-0.00473972] [0.05505052] [0.00030251]\n[-0.562431, -0.3405416, 10.29896]\nimage:  14\n[-0.32318383] [-0.12564464] [10.84702966] [-0.00410092] [0.05692652] [0.00017343]\n[-0.6093087, -0.368925, 11.15757]\nimage:  15\n[-0.37829023] [-0.13293541] [11.7015326] [-0.00486493] [0.05813844] [-0.00110331]\n[-0.6562052, -0.3973964, 12.01541]\nimage:  16\n[-0.43909882] [-0.14959942] [12.56203477] [-0.00721502] [0.0598978] [0.00113799]\n[-0.7018788, -0.4239119, 12.86965]\nimage:  17\n[-0.48842963] [-0.14229667] [13.43325776] [-0.01141969] [0.06196467] [0.00186507]\n[-0.7498241, -0.4540039, 13.73146]\nimage:  18\n[-0.55450795] [-0.15812051] [14.30690651] [-0.01328296] [0.06360621] [0.00590583]\n[-0.7992511, -0.484077, 14.60026]\nimage:  19\n[-0.62285927] [-0.17835807] [15.19037095] [-0.01307359] [0.06439737] [0.00705167]\n[-0.8546642, -0.515507, 15.47957]\nimage:  20\n[-0.68031933] [-0.20269915] [16.08376992] [-0.01114569] [0.06603054] [0.00579434]\n[-0.9072868, -0.5464705, 16.3694]\nimage:  21\n[-0.74969779] [-0.21964571] [16.98355117] [-0.00978573] [0.06715933] [0.00641362]\n[-0.9609163, -0.5783595, 17.26896]\nimage:  22\n[-0.81753034] [-0.23536409] [17.88107272] [-0.00973493] [0.06789458] [0.00555946]\n[-1.011589, -0.6092403, 18.17318]\nimage:  23\n[-0.88922645] [-0.25120622] [18.7864405] [-0.01092883] [0.06933164] [0.0056061]\n[-1.066256, -0.6387363, 19.08411]\nimage:  24\n[-0.96542376] [-0.26578426] [19.7011348] [-0.01199064] [0.06981655] [0.0042465]\n[-1.118651, -0.6686219, 19.99722]\nimage:  25\n[-1.04029297] [-0.28310473] [20.62024226] [-0.01051463] [0.07000221] [0.0045109]\n[-1.17184, -0.6990778, 20.91368]\nimage:  26\n[-1.11230961] [-0.30166574] [21.5422832] [-0.00748589] [0.06977297] [0.00618485]\n[-1.224279, -0.7287421, 21.84042]\nimage:  27\n[-1.18679105] [-0.32308248] [22.4595613] [-0.00367831] [0.06871686] [0.0070903]\n[-1.280807, -0.7604717, 22.77432]\nimage:  28\n[-1.26370618] [-0.34233353] [23.40190937] [-0.00090551] [0.06672302] [0.00693308]\n[-1.334841, -0.7929673, 23.70953]\nimage:  29\n[-1.33001167] [-0.35255328] [24.3604717] [-0.00027353] [0.0652444] [0.00697965]\n[-1.385747, -0.8209244, 24.65175]\nimage:  30\n[-1.4031182] [-0.37300096] [25.31163859] [-0.00306119] [0.06350694] [0.00800331]\n[-1.436633, -0.8456208, 25.59694]\nimage:  31\n[-1.47897619] [-0.38869649] [26.25168018] [-0.00801903] [0.06201764] [0.00935088]\n[-1.487044, -0.8702127, 26.54471]\nimage:  32\n[-1.54233824] [-0.40622375] [27.19681067] [-0.01079425] [0.06062395] [0.00871623]\n[-1.538025, -0.8971121, 27.49627]\nimage:  33\n[-1.61295548] [-0.42861319] [28.14176632] [-0.00958174] [0.05941063] [0.00656516]\n[-1.586551, -0.9254151, 28.45466]\nimage:  34\n[-1.66810702] [-0.42995852] [29.11334384] [-0.00536726] [0.05994635] [0.00403928]\n[-1.633363, -0.955563, 29.42293]\nimage:  35\n[-1.70260115] [-0.46212341] [30.07797541] [-0.00105168] [0.06176542] [-6.06145697e-05]\n[-1.680971, -0.9838377, 30.39839]\nimage:  36\n[-1.75302995] [-0.48011196] [31.0548545] [-0.00135509] [0.06289921] [-0.00773713]\n[-1.728893, -1.011772, 31.37765]\nimage:  37\n[-1.80972453] [-0.48893296] [32.02417363] [-0.00544641] [0.06433815] [-0.01003924]\n[-1.768976, -1.036363, 32.35714]\nimage:  38\n[-1.88470501] [-0.51143374] [33.00538935] [-0.00940392] [0.0654684] [-0.00908]\n[-1.815834, -1.059789, 33.33631]\nimage:  39\n[-1.89931381] [-0.54557546] [33.93736359] [-0.00951589] [0.06910117] [-0.00830237]\n[-1.870663, -1.088016, 34.32021]\nimage:  40\n[-1.98436168] [-0.57286409] [34.92165729] [-0.00827881] [0.06915771] [-0.00743413]\n[-1.92978, -1.12988, 35.33097]\nimage:  41\n[-2.06476972] [-0.5978684] [35.90276543] [-0.00573309] [0.06987614] [-0.00360661]\n[-1.993748, -1.194548, 36.38751]\nimage:  42\n[-2.14911317] [-0.61394897] [36.87890985] [-0.00485818] [0.07024599] [-0.00302324]\n[-2.061112, -1.249881, 37.4285]\nimage:  43\n[-2.21347572] [-0.6392612] [37.83082816] [-0.00222033] [0.07102493] [-0.0014167]\n[-2.126953, -1.305052, 38.47151]\nimage:  44\n[-2.28473807] [-0.64468358] [38.8276158] [0.00036922] [0.07098906] [-0.00211459]\n[-2.190967, -1.349142, 39.50365]\nimage:  45\n[-2.37168052] [-0.66491643] [39.80523406] [0.00265015] [0.07113272] [0.00430842]\n[-2.256115, -1.393047, 40.53855]\nimage:  46\n[-2.44886176] [-0.68469858] [40.79596296] [0.00218513] [0.07096919] [0.00479969]\n[-2.32994, -1.426813, 41.56111]\nimage:  47\n[-2.51896005] [-0.69624324] [41.78799117] [0.00052076] [0.0708986] [0.00494989]\n[-2.399728, -1.460731, 42.58303]\nimage:  48\n[-2.60690031] [-0.71295355] [42.77639262] [-0.00189833] [0.07031954] [0.00787582]\n[-2.465214, -1.489501, 43.59302]\nimage:  49\n[-2.69693798] [-0.73393439] [43.76625817] [-0.00186478] [0.07042704] [0.00833653]\n[-2.535885, -1.52285, 44.5979]\nimage:  50\n[-2.7746553] [-0.75269024] [44.74953766] [-0.00048221] [0.07121365] [0.00695007]\n[-2.600016, -1.559885, 45.59882]\nimage:  51\n[-2.85872229] [-0.76858676] [45.73550336] [0.00038218] [0.07157245] [0.00781926]\n[-2.661881, -1.593756, 46.59803]\nimage:  52\n[-2.94408388] [-0.78360084] [46.70876562] [-0.00363853] [0.07150369] [0.01060668]\n[-2.728914, -1.629817, 47.59275]\nimage:  53\n[-3.03056299] [-0.7982506] [47.6720539] [-0.00799011] [0.07217503] [0.01139496]\n[-2.800794, -1.664529, 48.57856]\nimage:  54\n[-3.11193437] [-0.81820933] [48.63801634] [-0.00927781] [0.07247029] [0.01238021]\n[-2.871336, -1.697621, 49.556]\nimage:  55\n[-3.19123717] [-0.83751005] [49.61154682] [-0.00579487] [0.07227283] [0.01100662]\n[-2.937935, -1.729013, 50.53773]\nimage:  56\n[-3.26678966] [-0.85780503] [50.59128609] [-0.00258283] [0.07232781] [0.00916421]\n[-3.002463, -1.766742, 51.51845]\nimage:  57\n[-3.34733151] [-0.87547472] [51.55797651] [-0.00191722] [0.07219619] [0.00753372]\n[-3.065844, -1.798994, 52.49501]\nimage:  58\n[-3.41444856] [-0.89491208] [52.51689884] [-0.00290133] [0.07241259] [0.00439872]\n[-3.130185, -1.830051, 53.46498]\nimage:  59\n[-3.48246141] [-0.91129667] [53.47465426] [-0.00421503] [0.07277711] [0.00170935]\n[-3.19152, -1.858398, 54.42804]\nimage:  60\n[-3.56301331] [-0.92616613] [54.42693736] [-0.00343222] [0.07340063] [0.00106918]\n[-3.248811, -1.886487, 55.39178]\nimage:  61\n[-3.62790579] [-0.93706625] [55.37938844] [0.00029457] [0.07449172] [-0.00167012]\n[-3.310922, -1.913841, 56.35039]\nimage:  62\n[-3.70155477] [-0.94611217] [56.33213092] [0.00488896] [0.07482737] [-0.00226327]\n[-3.371514, -1.938229, 57.31251]\nimage:  63\n[-3.78162199] [-0.95190831] [57.27898282] [0.00657529] [0.0750735] [-5.04163393e-05]\n[-3.438994, -1.956763, 58.274]\nimage:  64\n[-3.86140726] [-0.95971454] [58.20502427] [0.00206996] [0.07624682] [0.0013761]\n[-3.511313, -1.975962, 59.2254]\nimage:  65\n[-3.93585673] [-0.96684505] [59.11459041] [-0.00615914] [0.07754829] [0.00299069]\n[-3.579193, -1.998111, 60.16633]\nimage:  66\n[-4.02742699] [-0.98408444] [60.00925273] [-0.01151111] [0.07771985] [0.00547604]\n[-3.641784, -2.021539, 61.09125]\nimage:  67\n[-4.11230956] [-1.00603752] [60.92396976] [-0.01105691] [0.07853587] [0.010778]\n[-3.703384, -2.049159, 62.00632]\nimage:  68\n[-4.1935192] [-1.03416421] [61.80702766] [-0.0089849] [0.07931775] [0.01393253]\n[-3.776035, -2.078109, 62.91678]\nimage:  69\n[-4.27236734] [-1.06222532] [62.68923242] [-0.00774361] [0.08032366] [0.01692239]\n[-3.84394, -2.112094, 63.81519]\nimage:  70\n[-4.36216288] [-1.09453529] [63.55815601] [-0.00801314] [0.08091493] [0.0189222]\n[-3.912602, -2.145353, 64.69786]\nimage:  71\n[-4.42930649] [-1.1291691] [64.40130252] [-0.00692089] [0.08276347] [0.02127946]\n[-3.978228, -2.173835, 65.56672]\nimage:  72\n[-4.518203] [-1.16713587] [65.23908787] [-0.00592266] [0.08358876] [0.02340342]\n[-4.046625, -2.201409, 66.42163]\nimage:  73\n[-4.58912716] [-1.1780077] [66.06800694] [-0.00598813] [0.08526612] [0.02297352]\n[-4.114442, -2.230822, 67.26455]\nimage:  74\n[-4.67122244] [-1.19394015] [66.88370922] [-0.00508445] [0.0862951] [0.02296193]\n[-4.179994, -2.258366, 68.09328]\nimage:  75\n[-4.74415413] [-1.20459571] [67.6834275] [-0.0027959] [0.08789406] [0.02532366]\n[-4.244856, -2.28331, 68.90994]\nimage:  76\n[-4.82093827] [-1.21535135] [68.4770007] [0.00093489] [0.08910916] [0.02655]\n[-4.313021, -2.307845, 69.71424]\nimage:  77\n[-4.89583048] [-1.22911166] [69.24601354] [0.00236452] [0.09090616] [0.0300675]\n[-4.381935, -2.329476, 70.50799]\nimage:  78\n[-4.97912765] [-1.24587372] [69.99592899] [-0.00198803] [0.09208596] [0.03342747]\n[-4.44551, -2.355391, 71.28437]\nimage:  79\n[-5.0510131] [-1.26104848] [70.72201235] [-0.00954669] [0.09347755] [0.03402758]\n[-4.514875, -2.382091, 72.03735]\nimage:  80\n[-5.12218832] [-1.27305335] [71.42889523] [-0.01571522] [0.09500662] [0.03381372]\n[-4.58021, -2.409731, 72.76791]\nimage:  81\n[-5.20162059] [-1.28281993] [72.12864537] [-0.01754624] [0.09524869] [0.03507819]\n[-4.644343, -2.432982, 73.48065]\nimage:  82\n[-5.27599091] [-1.30670148] [72.79930251] [-0.01414836] [0.09596002] [0.03801009]\n[-4.709494, -2.459523, 74.17539]\nimage:  83\n[-5.34938904] [-1.33190718] [73.45442647] [-0.01193127] [0.09710436] [0.03852149]\n[-4.77573, -2.490277, 74.85147]\nimage:  84\n[-5.4186851] [-1.35232604] [74.08641288] [-0.01525537] [0.09799352] [0.0360175]\n[-4.837515, -2.525955, 75.50744]\nimage:  85\n[-5.45781302] [-1.35711023] [74.70218365] [-0.02108326] [0.09878914] [0.0282303]\n[-4.891889, -2.556654, 76.13828]\nimage:  86\n[-5.53214468] [-1.38018387] [75.30418974] [-0.02564727] [0.09711435] [0.02478922]\n[-4.937677, -2.585469, 76.7501]\nimage:  87\n[-5.60070483] [-1.38997751] [75.89360468] [-0.02676647] [0.09363357] [0.02757373]\n[-4.985837, -2.616742, 77.34409]\nimage:  88\n[-5.67305741] [-1.39878504] [76.47288908] [-0.0248997] [0.08906557] [0.03263191]\n[-5.039038, -2.646048, 77.92534]\nimage:  89\n[-5.7271038] [-1.41428907] [77.03273574] [-0.02228608] [0.0840631] [0.03123718]\n[-5.092732, -2.675699, 78.49464]\nimage:  90\n[-5.75660211] [-1.43451783] [77.58372827] [-0.01824181] [0.07869024] [0.02755531]\n[-5.133801, -2.70184, 79.04953]\nimage:  91\n[-5.796171] [-1.46073561] [78.11540058] [-0.01463932] [0.07004609] [0.02328816]\n[-5.159772, -2.729207, 79.5923]\nimage:  92\n[-5.7911326] [-1.49933834] [78.62613669] [-0.01405444] [0.06098397] [0.02683342]\n[-5.183357, -2.7568, 80.12304]\nimage:  93\n[-5.82137982] [-1.51427529] [79.13242589] [-0.01503287] [0.04568303] [0.03232114]\n[-5.208269, -2.780022, 80.63455]\nimage:  94\n[-5.84851177] [-1.53434934] [79.62425541] [-0.01447628] [0.02684847] [0.03752153]\n[-5.235209, -2.801727, 81.13538]\nimage:  95\n[-5.83950988] [-1.55320682] [80.10928157] [-0.01379997] [0.00461954] [0.03599215]\n[-5.248892, -2.822088, 81.62286]\nimage:  96\n[-5.81211346] [-1.56768382] [80.58552924] [-0.01325281] [-0.02188851] [0.03263798]\n[-5.236828, -2.839863, 82.09701]\nimage:  97\n[-5.79171918] [-1.6095515] [81.03819024] [-0.01022127] [-0.05287586] [0.03149488]\n[-5.207469, -2.859306, 82.55594]\nimage:  98\n[-5.74977328] [-1.63241453] [81.48876828] [-0.00859553] [-0.08704591] [0.03128914]\n[-5.163543, -2.878004, 83.00846]\nimage:  99\n[-5.6721116] [-1.64551436] [81.93397211] [-0.00843525] [-0.12488842] [0.03131968]\n[-5.10562, -2.895751, 83.45454]\nimage:  100\n[-5.55820723] [-1.65209233] [82.36800159] [-0.00917701] [-0.16627001] [0.03170801]\n[-5.02956, -2.911918, 83.8853]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from numpy.linalg import inv, pinv\n",
    "import matplotlib.pyplot as plt\n",
    "import time as t\n",
    "from helpers import *\n",
    "\n",
    "def extract_keypoints_surf(img1, img2, K, baseline):\n",
    "    \"\"\"\n",
    "    use surf to detect keypoint features\n",
    "    remember to include a Lowes ratio test\n",
    "    input: img1, img2: the previous and current image\n",
    "    K: camera matrix\n",
    "    baseline: the length of baseline\n",
    "    we use img1 and img2 to reconstruct 3D object points, then use 2D image\n",
    "    points in img1(reference image) to do PnP. \n",
    "    \"\"\"\n",
    "    # So first extract surf features\n",
    "    surf = cv2.xfeatures2d_SURF.create()\n",
    "    kp1, des1 = surf.detectAndCompute(img1, None)\n",
    "    kp2, des2 = surf.detectAndCompute(img2, None)\n",
    "    # Flann is more stable\n",
    "    matcher = cv2.FlannBasedMatcher()\n",
    "    matches = matcher.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x:x.distance)\n",
    "    match_points1 = []\n",
    "    match_points2 = []\n",
    "    for m in matches:\n",
    "        match_points1.append(kp1[m.queryIdx].pt)\n",
    "        match_points2.append(kp2[m.trainIdx].pt)\n",
    "    p1 = np.array(match_points1).astype(np.float32)\n",
    "    p2 = np.array(match_points2).astype(np.float32)\n",
    "\n",
    "    ##### ############# ##########\n",
    "    ##### Do Triangulation #######\n",
    "    ##### ########################\n",
    "    #project the feature points to 3D with triangulation\n",
    "    \n",
    "    #projection matrix for Left and Right Image\n",
    "    M_left = K.dot(np.hstack((np.eye(3), np.zeros((3, 1)))))\n",
    "    M_rght = K.dot(np.hstack((np.eye(3), np.array([[-baseline, 0, 0]]).T)))\n",
    "\n",
    "    p1_flip = np.vstack((p1.T, np.ones((1, p1.shape[0]))))\n",
    "    p2_flip = np.vstack((p2.T, np.ones((1, p2.shape[0]))))\n",
    "\n",
    "    P = cv2.triangulatePoints(M_left, M_rght, p1_flip[:2], p2_flip[:2])\n",
    "\n",
    "    # Normalize homogeneous coordinates (P->Nx4  [N,4] is the normalizer/scale)\n",
    "    P = P / P[3]\n",
    "    land_points = P[:3]\n",
    "\n",
    "    return land_points.T, p1\n",
    "    \n",
    "def featureTracking(img_1, img_2, p1, world_points):\n",
    "    \"\"\"\n",
    "    track the features of img_1 in img_2 via optical flow\n",
    "    p1 and world_points are 2D and 3D points respectively\n",
    "    return the tracked prev_points(p1), next_points(p2), world_points(3d points)\n",
    "    \"\"\"\n",
    "    params = dict(winSize=(21, 21),maxLevel=3,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "    p2, status,_ = cv2.calcOpticalFlowPyrLK(img_1, img_2, p1, None, **params)\n",
    "    idx = np.array(status==1).ravel()\n",
    "    p1 = p1[idx]\n",
    "    p2 = p2[idx]\n",
    "    world_points = world_points[idx]\n",
    "    return world_points, p1, p2\n",
    "\n",
    "def playImageSequence(left_img, right_img, K):\n",
    "\n",
    "    baseline = 0.54\n",
    "\n",
    "    ##### ################################# #######\n",
    "    ##### Get 3D points Using Triangulation #######\n",
    "    ##### #########################################\n",
    "    \"\"\"\n",
    "    Implement step 1.2 and 1.3\n",
    "    Store the features in 'reference_2D' and the 3D points (landmarks) in 'landmark_3D'\n",
    "    hint: use 'extract_keypoints_surf' above\n",
    "    \"\"\"\n",
    "    landmark_3D, reference_2D = extract_keypoints_surf(left_img, right_img, K, baseline)\n",
    "    # reference\n",
    "    reference_img = left_img\n",
    "\n",
    "    # Groundtruth for plot\n",
    "    truePose = getTruePose()\n",
    "    traj = np.zeros((600, 600, 3), dtype=np.uint8)\n",
    "    maxError = 0\n",
    "\n",
    "    for i in range(0, 101):\n",
    "        print('image: ', i)\n",
    "        curImage = getLeftImage(i)\n",
    "        curImage_R = getRightImage(i)\n",
    "\n",
    "        ##### ############################################################# #######\n",
    "        ##### Calculate 2D and 3D feature correspndances in t=T-1, and t=T  #######\n",
    "        ##### #####################################################################\n",
    "        \"\"\"\n",
    "        Implement step 2.2)\n",
    "        Remember this is a part of a loop, so the initial features are already\n",
    "        provided in step 1)-1.3) outside the loop in 'reference_2D' and 'landmark_3D'\n",
    "        \"\"\"\n",
    "        landmark_3D, reference_2D, current_2D = featureTracking(reference_img, curImage, \n",
    "        reference_2D, landmark_3D)\n",
    "        ##### ################################# #######\n",
    "        ##### Calculate relative pose using PNP #######\n",
    "        ##### #########################################\n",
    "        \"\"\"\n",
    "        Implement step 2.3)\n",
    "        \"\"\"\n",
    "        _, rvec, tvec,_ = cv2.solvePnPRansac(landmark_3D,current_2D, K, None)\n",
    "        ##### ####################################################### #######\n",
    "        ##### Get Pose and Tranformation Matrix in world coordionates #######\n",
    "        ##### ###############################################################\n",
    "        rot, _ = cv2.Rodrigues(rvec)\n",
    "        tvec = -rot.T.dot(tvec)  # coordinate transformation, from camera to world. What is the XYZ of the camera wrt World\n",
    "        inv_transform = np.hstack((rot.T, tvec))  # inverse transform. A tranform projecting points from the camera frame to the world frame\n",
    "\n",
    "        ##### ################################# #######\n",
    "        ##### Get 3D points Using Triangulation #######\n",
    "        ##### #########################################\n",
    "        # re-obtain the 3D points\n",
    "        \"\"\"\n",
    "        Implement step 2.4)\n",
    "        \"\"\"\n",
    "        landmark_3D_new, reference_2D_new = extract_keypoints_surf(curImage, curImage_R, K, baseline)\n",
    "        #Project the points from camera to world coordinates\n",
    "        reference_2D = reference_2D_new.astype('float32')\n",
    "        landmark_3D = inv_transform.dot(np.vstack((landmark_3D_new.T, np.ones((1, landmark_3D_new.shape[0])))))\n",
    "        landmark_3D = landmark_3D.T\n",
    "\n",
    "        ##### ####################### #######\n",
    "        ##### Done, Next image please #######\n",
    "        ##### ###############################\n",
    "        reference_img = curImage\n",
    "        i = max([i-1,0])\n",
    "        ##### ################################## #######\n",
    "        ##### START OF Print and visualize stuff #######\n",
    "        ##### ##########################################\n",
    "        # draw images\n",
    "        draw_x, draw_y = int(tvec[0]) + 300, 600-(int(tvec[2]) + 100)\n",
    "        true_x, true_y = int(truePose[i][3]) + 300, 600-(int(truePose[i][11]) + 100)\n",
    "\n",
    "        curError = np.sqrt(\n",
    "            (tvec[0] - truePose[i][3]) ** 2 +\n",
    "            (tvec[1] - truePose[i][7]) ** 2 +\n",
    "            (tvec[2] - truePose[i][11]) ** 2)\n",
    "        \n",
    "        if (curError > maxError):\n",
    "            maxError = curError\n",
    "\n",
    "        print(tvec[0],tvec[1],tvec[2], rvec[0], rvec[1], rvec[2])\n",
    "        print([truePose[i][3], truePose[i][7], truePose[i][11]])\n",
    "        \n",
    "        text = \"Coordinates: x ={0:02f}m y = {1:02f}m z = {2:02f}m\".format(float(tvec[0]), float(tvec[1]),float(tvec[2]))\n",
    "        cv2.circle(traj, (draw_x, draw_y), 1, (0, 0, 255), 2)\n",
    "        cv2.circle(traj, (true_x, true_y), 1, (255, 0, 0), 2)\n",
    "        cv2.rectangle(traj, (10, 30), (550, 50), (0, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(traj, text, (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, 8)\n",
    "\n",
    "        h1, w1 = traj.shape[:2]\n",
    "        h2, w2 = curImage.shape[:2]\n",
    "        vis = np.zeros((max(h1, h2), w1 + w2, 3), np.uint8)\n",
    "        vis[:h1, :w1, :3] = traj\n",
    "        vis[:h2, w1:w1 + w2, :3] = np.dstack((np.dstack((curImage,curImage)),curImage))\n",
    "\n",
    "        cv2.imshow(\"Trajectory\", vis)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27: break\n",
    "\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Maximum Error: ', maxError)\n",
    "    ##### ################################ #######\n",
    "    ##### END OF Print and visualize stuff #######\n",
    "    ##### ########################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    left_img = getLeftImage(0)\n",
    "    right_img = getRightImage(0)\n",
    "\n",
    "    K = getK()\n",
    "\n",
    "    playImageSequence(left_img, right_img, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge \n",
    "The current implementation only uses features computed at the current timestep. However, as we process more images we potentially have a lot of features from previous timesteps that are still valid. The challenge is to expand the `extract_keypoints_surf(..., refPoints)` function by giving it old reference points. You should then combine your freshly computed features with the old features and remove all duplicates. This requires you to keep track of old features and 3D points.\n",
    "\n",
    "Hint 1: look in `helpers.py` for removing duplicates.\n",
    "\n",
    "Hint 2: you are not interested in points that are behind you, so remember to remove points that are negative in the direction you move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "image:  0\n"
    },
    {
     "ename": "NameError",
     "evalue": "name 'truePose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-99b33a439c81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0mplayImageSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-99b33a439c81>\u001b[0m in \u001b[0;36mplayImageSequence\u001b[1;34m(left_img, right_img, K)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# draw images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mdraw_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtrue_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruePose\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruePose\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         curError = np.sqrt(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'truePose' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from numpy.linalg import inv, pinv\n",
    "import matplotlib.pyplot as plt\n",
    "import time as t\n",
    "from helpers import *\n",
    "import copy\n",
    "\n",
    "def extract_keypoints_surf(img1, img2, K, baseline, old_p, old_l):\n",
    "    surf = cv2.xfeatures2d_SURF.create()\n",
    "    kp1, des1 = surf.detectAndCompute(img1, None)\n",
    "    kp2, des2 = surf.detectAndCompute(img2, None)\n",
    "    matcher = cv2.FlannBasedMatcher()\n",
    "    matches = matcher.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x:x.distance)\n",
    "    match_points1 = []\n",
    "    match_points2 = []\n",
    "    for m in matches:\n",
    "        match_points1.append(kp1[m.queryIdx].pt)\n",
    "        match_points2.append(kp2[m.trainIdx].pt)\n",
    "    p1 = np.array(match_points1).astype(np.float32)\n",
    "    p2 = np.array(match_points2).astype(np.float32)\n",
    "    if len(old_p)<1:\n",
    "        old_p=p1\n",
    "    else:\n",
    "        idx = removeDuplicate(copy.deepcopy(p1), old_p, radius=5)\n",
    "        p1 = p1[idx]\n",
    "        p2 = p2[idx]\n",
    "        old_p = np.vstack((old_p, p1))\n",
    "\n",
    "    ##### ############# ##########\n",
    "    ##### Do Triangulation #######\n",
    "    ##### ########################\n",
    "    #project the feature points to 3D with triangulation\n",
    "    \n",
    "    #projection matrix for Left and Right Image\n",
    "    M_left = K.dot(np.hstack((np.eye(3), np.zeros((3, 1)))))\n",
    "    M_rght = K.dot(np.hstack((np.eye(3), np.array([[-baseline, 0, 0]]).T)))\n",
    "\n",
    "    p1_flip = np.vstack((p1.T, np.ones((1, p1.shape[0]))))\n",
    "    p2_flip = np.vstack((p2.T, np.ones((1, p2.shape[0]))))\n",
    "\n",
    "    P = cv2.triangulatePoints(M_left, M_rght, p1_flip[:2], p2_flip[:2])\n",
    "\n",
    "    # Normalize homogeneous coordinates (P->Nx4  [N,4] is the normalizer/scale)\n",
    "    P = P / P[3]\n",
    "    land_points = P[:3]\n",
    "    land_points = land_points.T\n",
    "\n",
    "    if len(old_l)<1:\n",
    "        old_l=land_points\n",
    "    else:\n",
    "        old_l = np.vstack((old_l, land_points))\n",
    "    return old_l ,old_p\n",
    "    \n",
    "def featureTracking(img_1, img_2, p1, world_points):\n",
    "    \"\"\"\n",
    "    track the features of img_1 in img_2 via optical flow\n",
    "    p1 and world_points are 2D and 3D points respectively\n",
    "    return the tracked prev_points(p1), next_points(p2), world_points(3d points)\n",
    "    \"\"\"\n",
    "    params = dict(winSize=(21, 21),maxLevel=3,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "    p2, status,_ = cv2.calcOpticalFlowPyrLK(img_1, img_2, p1, None, **params)\n",
    "    idx = np.array(status==1).ravel()\n",
    "    p1 = p1[idx]\n",
    "    p2 = p2[idx]\n",
    "    world_points = world_points[idx]\n",
    "    return world_points, p1, p2\n",
    "\n",
    "def playImageSequence(left_img, right_img, K):\n",
    "\n",
    "    baseline = 0.54\n",
    "\n",
    "    ##### ################################# #######\n",
    "    ##### Get 3D points Using Triangulation #######\n",
    "    ##### #########################################\n",
    "    \"\"\"\n",
    "    Implement step 1.2 and 1.3\n",
    "    Store the features in 'reference_2D' and the 3D points (landmarks) in 'landmark_3D'\n",
    "    hint: use 'extract_keypoints_surf' above\n",
    "    \"\"\"\n",
    "    landmark_3D = []\n",
    "    reference_2D = []\n",
    "    prevPose = []\n",
    "    landmark_3D,reference_2D = extract_keypoints_surf(left_img, right_img, K, baseline, reference_2D, landmark_3D)\n",
    "    # reference\n",
    "    reference_img = left_img\n",
    "\n",
    "    # Groundtruth for plot\n",
    "    truePose = getTruePose()\n",
    "    traj = np.zeros((600, 600, 3), dtype=np.uint8)\n",
    "    maxError = 0\n",
    "\n",
    "    for i in range(0, 101):\n",
    "        print('image: ', i)\n",
    "        curImage = getLeftImage(i)\n",
    "        curImage_R = getRightImage(i)\n",
    "\n",
    "        ##### ############################################################# #######\n",
    "        ##### Calculate 2D and 3D feature correspndances in t=T-1, and t=T  #######\n",
    "        ##### #####################################################################\n",
    "        \"\"\"\n",
    "        Implement step 2.2)\n",
    "        Remember this is a part of a loop, so the initial features are already\n",
    "        provided in step 1)-1.3) outside the loop in 'reference_2D' and 'landmark_3D'\n",
    "        \"\"\"\n",
    "        landmark_3D, reference_2D, current_2D = featureTracking(reference_img, curImage, \n",
    "        reference_2D, landmark_3D)\n",
    "        ##### ################################# #######\n",
    "        ##### Calculate relative pose using PNP #######\n",
    "        ##### #########################################\n",
    "        \"\"\"\n",
    "        Implement step 2.3)\n",
    "        \"\"\"\n",
    "        _, rvec, tvec,_ = cv2.solvePnPRansac(landmark_3D,current_2D, K, None)\n",
    "        ##### ####################################################### #######\n",
    "        ##### Get Pose and Tranformation Matrix in world coordionates #######\n",
    "        ##### ###############################################################\n",
    "        rot, _ = cv2.Rodrigues(rvec)\n",
    "        tvec = -rot.T.dot(tvec)  # coordinate transformation, from camera to world. What is the XYZ of the camera wrt World\n",
    "        inv_transform = np.hstack((rot.T, tvec))  # inverse transform. A tranform projecting points from the camera frame to the world frame\n",
    "        # abandon rebundant points(behind the direction)\n",
    "        if not i:\n",
    "            prevPose = tvec\n",
    "        else:\n",
    "            direction = tvec-prevPose\n",
    "            x = direction[0]/np.abs(direction[0])\n",
    "            y = direction[1]/np.abs(direction[1])\n",
    "            z = direction[2]/np.abs(direction[2])\n",
    "            idx = []\n",
    "            for j in range(landmark_3D.shape[0]):\n",
    "                p = landmark_3D[j,:]-tvec\n",
    "                p[0] = p[0]/np.abs(p[0])\n",
    "                p[1] = p[1]/np.abs(p[1])\n",
    "                p[2] = p[2]/np.abs(p[2])\n",
    "                if np.sum(p-[x,y,z])==0:\n",
    "                    idx.append(j)\n",
    "            landmark_3D = landmark_3D[idx]\n",
    "            reference_2D = reference_2D[idx]\n",
    "            prevPose = tvec\n",
    "\n",
    "        ##### ################################# #######\n",
    "        ##### Get 3D points Using Triangulation #######\n",
    "        ##### #########################################\n",
    "        # re-obtain the 3D points\n",
    "        \"\"\"\n",
    "        Implement step 2.4)\n",
    "        \"\"\"\n",
    "        landmark_3D_new, reference_2D_new= extract_keypoints_surf(curImage, curImage_R, K, baseline, reference_2D, landmark_3D)\n",
    "        #Project the points from camera to world coordinates\n",
    "        reference_2D = reference_2D_new.astype('float32')\n",
    "        landmark_3D = inv_transform.dot(np.vstack((landmark_3D_new.T, np.ones((1, landmark_3D_new.shape[0])))))\n",
    "        landmark_3D = landmark_3D.T\n",
    "\n",
    "        ##### ####################### #######\n",
    "        ##### Done, Next image please #######\n",
    "        ##### ###############################\n",
    "        reference_img = curImage\n",
    "        i = max([i-1,0])\n",
    "        ##### ################################## #######\n",
    "        ##### START OF Print and visualize stuff #######\n",
    "        ##### ##########################################\n",
    "        # draw images\n",
    "        draw_x, draw_y = int(tvec[0]) + 300, 600-(int(tvec[2]) + 100)\n",
    "        true_x, true_y = int(truePose[i][3]) + 300, 600-(int(truePose[i][11]) + 100)\n",
    "\n",
    "        curError = np.sqrt(\n",
    "            (tvec[0] - truePose[i][3]) ** 2 +\n",
    "            (tvec[1] - truePose[i][7]) ** 2 +\n",
    "            (tvec[2] - truePose[i][11]) ** 2)\n",
    "        \n",
    "        if (curError > maxError):\n",
    "            maxError = curError\n",
    "\n",
    "        print(tvec[0],tvec[1],tvec[2], rvec[0], rvec[1], rvec[2])\n",
    "        print([truePose[i][3], truePose[i][7], truePose[i][11]])\n",
    "        \n",
    "        text = \"Coordinates: x ={0:02f}m y = {1:02f}m z = {2:02f}m\".format(float(tvec[0]), float(tvec[1]),float(tvec[2]))\n",
    "        cv2.circle(traj, (draw_x, draw_y), 1, (0, 0, 255), 2)\n",
    "        cv2.circle(traj, (true_x, true_y), 1, (255, 0, 0), 2)\n",
    "        cv2.rectangle(traj, (10, 30), (550, 50), (0, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(traj, text, (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, 8)\n",
    "\n",
    "        h1, w1 = traj.shape[:2]\n",
    "        h2, w2 = curImage.shape[:2]\n",
    "        vis = np.zeros((max(h1, h2), w1 + w2, 3), np.uint8)\n",
    "        vis[:h1, :w1, :3] = traj\n",
    "        vis[:h2, w1:w1 + w2, :3] = np.dstack((np.dstack((curImage,curImage)),curImage))\n",
    "\n",
    "        cv2.imshow(\"Trajectory\", vis)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27: break\n",
    "\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Maximum Error: ', maxError)\n",
    "    ##### ################################ #######\n",
    "    ##### END OF Print and visualize stuff #######\n",
    "    ##### ########################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    left_img = getLeftImage(0)\n",
    "    right_img = getRightImage(0)\n",
    "\n",
    "    K = getK()\n",
    "\n",
    "    playImageSequence(left_img, right_img, K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}