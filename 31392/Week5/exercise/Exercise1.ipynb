{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global registration with RANSAC\n",
    "We are going to use open3d (http://www.open3d.org/) to handle  pointclouds and generation of pointclouds\n",
    "\n",
    "So make sure to call **pip install open3d**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor): # recolor the points\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None): # transforma source to targets\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in our pointclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"ICP/r2.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "# Show models side by side\n",
    "draw_registrations(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding features in pointclouds\n",
    "When working on point clouds it can be benefitial work on a downsampled version of the point cloud.\n",
    "you can use [```pointcloudname.voxel_down_sample()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html) where pointcloud is the name of your point cloud object.\n",
    "\n",
    "We also need to estimate the normals of the pointcloud points using [```pointcloudname.estimate_normals()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html)\n",
    "\n",
    "And finally find fpfh features or correspondance of the downsampled point clouds.\n",
    "[```o3d.registration.compute_fpfh_feature()```](http://www.open3d.org/docs/latest/python_api/open3d.registration.compute_fpfh_feature.html#open3d.registration.compute_fpfh_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "# Code\n",
    "def get_fpfh(cp):\n",
    "    cp = cp.voxel_down_sample(voxel_size)\n",
    "    cp.estimate_normals()\n",
    "    return cp, o3d.registration.compute_fpfh_feature(cp, o3d.geometry.KDTreeSearchParamHybrid(radius=5, max_nn=100))\n",
    "r1, f1 = get_fpfh(source)\n",
    "r2, f2 = get_fpfh(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ransac\n",
    "We will now attempt to use ransac to do a global registration of the two poinclouds.\n",
    "\n",
    "Using the function [```o3d.registration.registration_ransac_based_on_feature_matching```](http://www.open3d.org/docs/latest/python_api/open3d.registration.registration_ransac_based_on_feature_matching.html#open3d.registration.registration_ransac_based_on_feature_matching) from open3d\n",
    "\n",
    "\n",
    "Try to find the transformation from r1 to r2.\n",
    "```Python\n",
    "point_to_point =  o3d.registration.TransformationEstimationPointToPoint(False)\n",
    "```\n",
    "\n",
    "When using ransac focus on the arguments below the rest are optional\n",
    "```Python\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Call RANSAC here\n",
    "####\n",
    "point2point =  o3d.registration.TransformationEstimationPointToPoint(False)\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    r1, r2, \n",
    "    f1, f2, \n",
    "    voxel_size*1.5, \n",
    "point2point)\n",
    "draw_registrations(r1, r2, ransac_result.transformation, True)\n",
    "# ransac_result = ...\n",
    "# draw_registrations(source, target, ransac_result.transformation, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### A)\n",
    "    Can you get a decent transformation from r1 to r3?\n",
    "### B)\n",
    "    Try to use pruning to stop Ransac early. A pruning step takes fast pruning algorithms to quickly reject false matches early.\n",
    "\n",
    "Open3D provides the following pruning algorithms:\n",
    "\n",
    "- **CorrespondenceCheckerBasedOnDistance** checks if aligned point clouds are close (less than specified threshold).\n",
    "\n",
    "- **CorrespondenceCheckerBasedOnEdgeLength** checks if the lengths of any two arbitrary edges (line formed by two vertices) individually drawn from source and target correspondences are similar. This tutorial checks that ||edge_source||>0.9×||edge_target|| and ||edge_target||> 0.9×||edge_source|| are true.\n",
    "\n",
    "- **CorrespondenceCheckerBasedOnNormal** considers vertex normal affinity of any correspondences. It computes dot product of two normal vectors. It takes radian value for the threshold.\n",
    "\n",
    "\n",
    "You can also try tweaking the voxel_size\n",
    "```Python\n",
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "# Checkers\n",
    "c0 = o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "checker_list = [c0, c1, c2]\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)\n",
    "```\n",
    "\n",
    "### D)\n",
    "Try to use **RANSACConvergenceCriteria** to see how many iterations are needed for decent convergence for both point to point and point to plane.\n",
    "\n",
    "Replace point_to_point with point_to_plane.\n",
    "```Python\n",
    "point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "crit = o3d.registration.RANSACConvergenceCriteria(1000000, 100)\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_plane,\n",
    "    checkers = checker_list\n",
    "    criteria = crit)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = o3d.io.read_point_cloud(\"ICP/r3.pcd\")\n",
    "r3, f3 = get_fpfh(r3)\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    r1, r3, \n",
    "    f1, f3, \n",
    "    voxel_size*1.5, point2point)\n",
    "draw_registrations(r1, r3, ransac_result.transformation, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "# Checkers\n",
    "c0 = o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "checker_list = [c0, c1, c2]\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    r1, r3, \n",
    "    f1, f3, \n",
    "    distance_threshold,\n",
    "    point2point,\n",
    "    checkers = checker_list)\n",
    "draw_registrations(r1, r3, ransac_result.transformation, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "crit = o3d.registration.RANSACConvergenceCriteria(1000000, 100)\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    r1, r3, \n",
    "    f1, f3, \n",
    "    distance_threshold,\n",
    "    point_to_plane,\n",
    "    checkers = checker_list,\n",
    "    criteria = crit)\n",
    "draw_registrations(r1, r3, ransac_result.transformation, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}