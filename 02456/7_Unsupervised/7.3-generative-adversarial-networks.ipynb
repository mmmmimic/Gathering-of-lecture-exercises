{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "It is recommended to run this notebook on a GPU\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "plt.style.use([\"seaborn-deep\", \"seaborn-whitegrid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "Generative Adversarial Networks (GAN) [[Goodfellow, 2014]](https://arxiv.org/abs/1406.2661) have recently become a popular alternative to variational autoencoders for generative modelling and to a lesser extend semi-supervised learning. They also represent the state-of-the-art in modelling of realistic images and video just four years after their introduction. Below you can see a comparison of the development in GANs for generation of realistic faces from 2014 until today.\n",
    "\n",
    "<img src=\"../static_files/GAN-celebA.jpg\" alt=\"GAN performance over the years\" width=\"600px\"/>\n",
    "\n",
    "Different variants of GANs have also proven to perform well on tasks such inpainting, super-resolution and image-to-image translation. In this notebook we will again work with a subset of the MNIST-dataset in order to compare with VAEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "# The digit classes to use, these need to be in order because\n",
    "# we are using one-hot representation\n",
    "classes = np.arange(2)\n",
    "\n",
    "def one_hot(labels):\n",
    "    y = torch.eye(len(classes)) \n",
    "    return y[labels]\n",
    "\n",
    "# Define the train and test sets\n",
    "dset_train = MNIST(\"./\", train=True, download=True, transform=ToTensor(), target_transform=one_hot)\n",
    "dset_test  = MNIST(\"./\", train=False, transform=ToTensor(), target_transform=one_hot)\n",
    "\n",
    "def stratified_sampler(labels):\n",
    "    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "    indices = torch.from_numpy(indices)\n",
    "    return SubsetRandomSampler(indices)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train, batch_size=batch_size,\n",
    "                          sampler=stratified_sampler(dset_train.train_labels), pin_memory=cuda)\n",
    "test_loader  = DataLoader(dset_test, batch_size=batch_size, \n",
    "                          sampler=stratified_sampler(dset_test.test_labels), pin_memory=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial learning\n",
    "\n",
    "The training process of a GAN can be seen as a two player game involving a discriminator network ($D$) and a generator network($G$). Intuitively, we can describe the role of the two networks as \"police\" and \"forger\", respectively. Given some empirical distribution $p(x)$, the forger wants to fool the police by creating samples that look like they come from $p(x)$. The police will then try to \"analayse each art piece\" to guess whether it is forged or not. This process leads the generator to eventually generate samples that are indistinguishable from the real data.\n",
    "\n",
    "<img src=\"../static_files/GAN.png\" alt=\"GAN diagram\" width=\"500px\"/>\n",
    "\n",
    "Below we define a deep convolutional generative adversarial network (DCGAN), introduced by [[Radford, 2015]](https://arxiv.org/abs/1511.06434). This means that both the discriminator and generator are deep convolutional networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "latent_dim = 100\n",
    "\n",
    "# The generator takes random `latent` noise and\n",
    "# turns it into an MNIST image.\n",
    "generator = nn.Sequential(\n",
    "    # nn.ConvTranspose2d can be seen as the inverse operation\n",
    "    # of Conv2d, where after convolution we arrive at an\n",
    "    # upscaled image.\n",
    "    nn.ConvTranspose2d(latent_dim, 256, kernel_size=3, stride=2),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "    nn.Sigmoid() # Image intensities are in [0, 1]\n",
    ").to(device)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# The discriminator takes an image (real or fake)\n",
    "# and decides whether it is generated or not.\n",
    "discriminator = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=4, stride=2),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    Flatten(),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "generator_optim = torch.optim.Adam(generator.parameters(), 2e-4, betas=(0.5, 0.999))\n",
    "discriminator_optim = torch.optim.Adam(discriminator.parameters(), 2e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GAN game\n",
    "\n",
    "The objective function can be formulated within the framework of game-theory, concretely as a zero-sum game. The optimum is therefore given by the *Nash equilibrium* between $D$ and $G$. Unfortunately, there exists no such algorithm capable of finding the Nash equilibrium directly, so we must instead resort to gradient descent, for which we arrive at the following objective function $V(D, G)$.\n",
    "\n",
    "$$\\min_{G}\\max_{D} V(D, G) = \\mathbb{E}_{x \\sim p(x)} [\\log D(x)] + \\mathbb{E}_{z \\sim p(z)} [\\log(1 - D(G(z)))]$$\n",
    "\n",
    "Where $x \\sim p(x)$ is sampled from the true distribution and $z \\sim p(z)$ is a sample from the noise distribution. To break down this objective we consider the first term $\\max_{D}\\mathbb{E}_{x \\sim p(x)} [\\log D(x)]$, which is the log-likelihood of the discriminator correctly classifying a data point as coming from the true distribution. The second term $\\min_{G}\\max_{D} \\mathbb{E}_{z \\sim p(z)} [\\log(1 - D(G(z)))]$ can be seen as a dual objective of the discriminator correctly rejecting a sample from the generator by maximising the likelihood, while simultaneously, the generator should minimise the chance of being \"caught\" by the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "tmp_img = \"tmp_gan_out.png\"\n",
    "discriminator_loss, generator_loss = [], []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    batch_d_loss, batch_g_loss = [], []\n",
    "    \n",
    "    for x, _ in train_loader:\n",
    "        batch_size = x.size(0)\n",
    "        # True data is given label 1, while fake data is given label 0\n",
    "        true_label = torch.ones(batch_size, 1).to(device)\n",
    "        fake_label = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        discriminator.zero_grad()\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        # Step 1. Send real data through discriminator\n",
    "        #         and backpropagate its errors.\n",
    "        x_true = Variable(x).to(device)        \n",
    "        output = discriminator(x_true)\n",
    "        \n",
    "        error_true = loss(output, true_label)\n",
    "        error_true.backward()\n",
    "        \n",
    "        # Step 2. Generate fake data G(z), where z ~ N(0, 1)\n",
    "        #         is a latent code.\n",
    "        z = torch.randn(batch_size, latent_dim, 1, 1)\n",
    "        z = Variable(z, requires_grad=False).to(device)\n",
    "        \n",
    "        x_fake = generator(z)\n",
    "            \n",
    "        # Step 3. Send fake data through discriminator\n",
    "        #         propagate error and update D weights.\n",
    "        # --------------------------------------------\n",
    "        # Note: detach() is used to avoid compounding generator gradients\n",
    "        output = discriminator(x_fake.detach()) \n",
    "        \n",
    "        error_fake = loss(output, fake_label)\n",
    "        error_fake.backward()\n",
    "        discriminator_optim.step()\n",
    "        \n",
    "        # Step 4. Send fake data through discriminator _again_\n",
    "        #         propagate the error of the generator and\n",
    "        #         update G weights.\n",
    "        output = discriminator(x_fake)\n",
    "        \n",
    "        error_generator = loss(output, true_label)\n",
    "        error_generator.backward()\n",
    "        generator_optim.step()\n",
    "        \n",
    "        batch_d_loss.append((error_true/(error_true + error_fake)).item())\n",
    "        batch_g_loss.append(error_generator.item())\n",
    "\n",
    "    discriminator_loss.append(np.mean(batch_d_loss))\n",
    "    generator_loss.append(np.mean(batch_g_loss))\n",
    "    \n",
    "    # -- Plotting --\n",
    "    f, axarr = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "    # Loss\n",
    "    ax = axarr[0]\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "\n",
    "    ax.plot(np.arange(epoch+1), discriminator_loss)\n",
    "    ax.plot(np.arange(epoch+1), generator_loss, linestyle=\"--\")\n",
    "    ax.legend(['Discriminator', 'Generator'])\n",
    "    \n",
    "    # Latent space samples\n",
    "    ax = axarr[1]\n",
    "    ax.set_title('Samples from generator')\n",
    "    ax.axis('off')\n",
    "\n",
    "    rows, columns = 8, 8\n",
    "    \n",
    "    # Generate data\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(rows*columns, latent_dim, 1, 1)\n",
    "        z = Variable(z, requires_grad=False).to(device)\n",
    "        x_fake = generator(z)\n",
    "    \n",
    "    canvas = np.zeros((28*rows, columns*28))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = i % columns + rows * j\n",
    "            canvas[i*28:(i+1)*28, j*28:(j+1)*28] = x_fake.data[idx]\n",
    "    ax.imshow(canvas, cmap='gray')\n",
    "    \n",
    "    plt.savefig(tmp_img)\n",
    "    plt.close(f)\n",
    "    display(Image(filename=tmp_img))\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    os.remove(tmp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments\n",
    "\n",
    "\n",
    "## Assignment 1 - Analyzing the GAN\n",
    "* Reduce the latent space dimension, is the generator still able to create convincing samples? Give an explanation for what you see (*hint: think of the generator as the inverse of a non-linear PCA*).\n",
    "* Try training the GAN a couple of times using different digits and latent space dimension; does training always converge? If it doesn't, what happens?\n",
    "* Consider the case when the generator is perfect, effectively meaning that any sample from $G(z)$ is indistinguishable from a sample from the true distribution. What is then the value $D(x)$ for any $x$? Is this value an optimum?\n",
    "\n",
    "## Optional assignment 2 - Conditional GANs\n",
    "Take a look at conditional GANs [[Mirza and Osindero, 2014]](https://arxiv.org/abs/1411.1784). In essence, we add additional information through the variable $y$ to the GAN\n",
    "\n",
    "* Assume that the following about the mutual information between $X$ and $Y$: $I(X, Y) > 0$. Now prove that knowing $Y$ reduces our uncertainty about $X$, equivalently $H(X|Y) \\leq H(X)$. Explain why this makes the GAN better.\n",
    "* Explain how a conditional GAN can be used for semi-supervised learning. How would you formulate the objective (loss) function?\n",
    "* Implement a conditional GAN by feeding in the label information for each digit into the generator and discriminator. You can use the code below as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "latent_dim = 100\n",
    "label_dim = len(classes)\n",
    "\n",
    "# The generator takes random `latent` noise and\n",
    "# a label it into an MNIST image conditioned on label\n",
    "# p(x|y).\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        \n",
    "        self.conv_z = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 256, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv_y = nn.Sequential(\n",
    "            nn.ConvTranspose2d(label_dim, 256, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # Merge information and send through network.\n",
    "        x = torch.cat([?, ?], dim=1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "        self.conv_x = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.conv_y = nn.Sequential(\n",
    "            nn.Conv2d(label_dim, 64, kernel_size=4, stride=2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Flatten(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # Merge information and send through network.\n",
    "        x = torch.cat([?, ?], dim=1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "generator = ConditionalGenerator().to(device)\n",
    "discriminator = ConditionalDiscriminator().to(device)\n",
    "\n",
    "generator_optim = torch.optim.Adam(generator.parameters(), 2e-4, betas=(0.5, 0.999))\n",
    "discriminator_optim = torch.optim.Adam(discriminator.parameters(), 2e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):    \n",
    "    for x, y in train_loader:\n",
    "        batch_size = x.size(0)\n",
    "        # True data is given label 1, while fake data is given label 0\n",
    "        true_label = torch.ones(batch_size, 1).to(device)\n",
    "        fake_label = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        x_true = Variable(x).to(device)\n",
    "        y = Variable(y).to(device)\n",
    "        \n",
    "        # Create random noise\n",
    "        z = torch.randn(batch_size, latent_dim, 1, 1)\n",
    "        z = Variable(z, requires_grad=False).to(device)\n",
    "        \n",
    "        # --- Define you training here ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
