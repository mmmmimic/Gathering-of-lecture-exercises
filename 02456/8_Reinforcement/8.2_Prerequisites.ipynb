{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "> By Jonas Busk ([jbusk@dtu.dk](mailto:jbusk@dtu.dk))\n",
    "\n",
    "**2019 update:** Changes have been made to the display of environments due to the previous `viewer` being incompatible with newer versions of Gym.\n",
    "\n",
    "In this lab we will create neural network reinforcement learning agents with [PyTorch](https://pytorch.org/) to navigate various environments from [OpenAI Gym](https://gym.openai.com/) developed by [OpenAI](https://openai.com/).\n",
    "\n",
    "Please refer to the [docs](https://gym.openai.com/docs/) on how to get started with Gym. You are also encouraged to take a look at this short [post on the OpenAI blog](https://blog.openai.com/openai-gym-beta/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Below is a brief guide on how to install OpenAI Gym. For more details, please refer to the repository on [GitHub](https://github.com/openai/gym) and the [docs](https://gym.openai.com/docs).\n",
    "\n",
    "You can do a minimal install of the packaged version of Gym directly from PyPI:\n",
    "\n",
    "```\n",
    "pip install gym\n",
    "```\n",
    "\n",
    "Or you can perform a minimal install from GitHub:\n",
    "\n",
    "```\n",
    "git clone https://github.com/openai/gym.git\n",
    "cd gym\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "If you like, you can do a quick pip install of Gym in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need an installation of `ffmpeg` locally. If you do not have it installed already, you can install it by one of the following commands depending on your system:\n",
    "\n",
    "```sudo apt-get install ffmpeg``` (Linux)\n",
    "\n",
    "```conda install -c conda-forge ffmpeg``` (Anaconda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an environment\n",
    "\n",
    "Here is a bare minimum example of running a Gym environment. This creates an instance of the [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) environment and runs until the rollout is done, taking random actions and rendering the environment at each step. With Gym installed, you should be able to see a small animation of the environment below.\n",
    "\n",
    "**Note:** you will likely not be able to render environments in a Google Colab instance. Therefore, it may be beneficial for you to run this week's notebooks locally and/or team up with another student if you do not have a local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "env = gym.make('CartPole-v0') # Create environment\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True) # Create wrapper to display environment\n",
    "env.reset() # Reset environment\n",
    "\n",
    "# Run environment\n",
    "while True:\n",
    "    env.render() # Render environment\n",
    "    action = env.action_space.sample() # Get a random action\n",
    "    _, _, done, _ = env.step(action) # Take a step\n",
    "    if done: break # Break if environment is done\n",
    "\n",
    "env.close() # Close environment\n",
    "\n",
    "def show_replay():\n",
    "    \"\"\"\n",
    "    Not-so-elegant way to display the MP4 file generated by the Monitor wrapper inside a notebook.\n",
    "    The Monitor wrapper dumps the replay to a local file that we then display as a HTML video object.\n",
    "    \"\"\"\n",
    "    import io\n",
    "    import base64\n",
    "    from IPython.display import HTML\n",
    "    video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return HTML(data='''\n",
    "        <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    "    .format(encoded.decode('ascii')))\n",
    "    \n",
    "show_replay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! You now have a working `Gym` environment that we can take actions in and render."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
