{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "02807: Project 1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7sVQeTkLYI2b"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlsPJUw7wCWZ"
      },
      "source": [
        "# 02807: Project 1\n",
        " \n",
        "## Practical information\n",
        " \n",
        "* This project must be completed in groups of 3 students.\n",
        "* This project must be handed in as a Google Colab notebook to the course site on DTU Inside. Go to the Assignments tab to upload your submission. \n",
        "* This project is due on Monday, November 2, 20:00.\n",
        "* Each group has to hand in *one* notebook with their solutions.\n",
        "* Your code must be written in Python.\n",
        "* For each question you should use exactly the cells provided for your solution\n",
        "* You should not remove the problem statements, and you should not modify the structure of the notebook.\n",
        "* Your notebook should be runnable, i.e., clicking in the code cells should display the result that you want to have assessed.\n",
        " \n",
        "## Colaboration policy\n",
        " \n",
        "* It is not allowed to collaborate on the exercises with students outside your group, except for discussing the text of the exercise with teachers and fellow students enrolled on the course in the same semester. \n",
        "* It is not allowed to exchange, hand-over or in any other way communicate solutions or parts of solutions to the exercises. \n",
        "* It is not allowed to use solutions from similar courses, or solutions found elsewhere."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP30rwxHDQyG"
      },
      "source": [
        "## Contribution table and grading\n",
        "\n",
        "* The total amount of points in the project is 105.\n",
        "* You have to indicate who has solved each part of each exercise in a **contribution table**. \n",
        "* The following is an example of a contributions table:\n",
        "\n",
        "|        | Exercise 1 | Exercise 2 | Exercise 3 | Exercise 4 |\n",
        "|--------|------------|------------|------------|------------|\n",
        "| **Part 1** | John       |    Mary        |     Ann       |   Mary, Ann         |\n",
        "| **Part 2** |     Mary       |    Mary        |   Ann         |    John, Ann        |\n",
        "| **Part 3** |     John, Mary, Ann       |      John, Ann      |   John         | **n.a.**      |\n",
        "| **Part 4** | **n.a.**       |  Ann          |     John, Mary       | **n.a.**       |\n",
        "| **Part 5** | **n.a.**     | John, Mary, Ann           | **n.a.**       | **n.a.**       |\n",
        "| **Part 6** | **n.a.**       | John, Mary, Ann           | **n.a.**      | **n.a.**      |\n",
        "\n",
        "* A group member can take credit for solving a part of an exercise only if they have contributed **substantially** to the solution. \n",
        "* Simple contributions, such as correcting a small bug or double-checking the results of functions, are not sufficient for taking credit for a solution.\n",
        "* Several group members can take credit for the same solution if they all have contributed substantially to it.\n",
        "* **Each group member must solve at least 105/3=35 points**. \n",
        "* **If no name is provided for an exercise's part, all group members will be assigned responsibility for it**.\n",
        "* Group members should decide amongst themselves how to collaborate on the project to meet the above-mentioned constraints.  \n",
        "* Grades are individual. The grade $\\text{grade}(m)$ for a group member $m$ ranges from 0 to 10 and is calculated as follows: \n",
        "\n",
        "  * $\\text{individual-score}(m) = \\frac{\\text{total number of points for the parts correctly solved by }m}{\\text{total number of points for the parts contributed by }m}$\n",
        "\n",
        "  * $\\text{group-score} = \\frac{\\text{total number of points correctly solved by any group member}}{\\text{total number of points in the project}}$\n",
        "\n",
        "  * $\\text{grade}(m) =  7.5 \\cdot \\text{individual-score}(m) + 2.5 \\cdot \\text{group-score}$\n",
        "\n",
        "* **Example**: in the contribution table above, suppose that all parts are solved correctly except for those of Exercise 4, which are both wrong. Then Ann's grade is calculated as follows:\n",
        "\n",
        "  * $\\text{individual-part}(Ann) = \\frac{2.5 + 2.5 + 10 + 10 + 5 + 10 + 5}{2.5 + 2.5 + 10 + 10 + 5 + 10 + 5 + 10 + 10} = \\frac{45}{65} = 0.692$\n",
        "\n",
        "  * $\\text{group-part} = \\frac{85}{105} = 0.809$\n",
        "\n",
        "  * $\\text{grade}(Ann) =  7.14$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vklet8XdRGVV"
      },
      "source": [
        "# Group declaration table \n",
        "\n",
        "This table must be filled before submission.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chiXA3CzRSA1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "d = {'Exercise 1' : [\"\", \"\", \"\", \"\", \"\", \"\"], \n",
        "     'Exercise 2' : [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
        "     'Exercise 3' : [\"\", \"\", \"\", \"\", \"\", \"\"], \n",
        "     'Exercise 4' : [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
        "     } \n",
        "  \n",
        "ct = pd.DataFrame(d, index =['Part 1','Part 2','Part 3','Part 4','Part 5','Part 6']) \n",
        "\n",
        "ct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d7aa1b0ad6979877450f9cd89e1e37289b51cf6e",
        "id": "CF8tC7Z8CgbW"
      },
      "source": [
        "# Introduction to the Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO8N4lj29u9w"
      },
      "source": [
        "![link text](https://ph-files.imgix.net/069dd825-cddf-4048-adde-8e81396c2c68?auto=format)\n",
        "\n",
        "\n",
        "You will be working with datasets obtained through the [The Movie Database (TMDb) API](https://developers.themoviedb.org/3/getting-started/introduction). The first dataset is part of the MovieLens Latest Full Dataset, comprising 26 million ratings on 45.000 movies from 27.000 users. Let's look at the features in this dataset.\n",
        "\n",
        "**Features**\n",
        "\n",
        "* **adult**: Indicates if the movie is X-Rated.\n",
        "* **belongs_to_collection**: A stringified dictionary with info on the movie series a particular film belongs to (e.g.: Lord of the Rings).\n",
        "* **budget**: The movie budget in dollars.\n",
        "* **genres**: A stringified list of dictionaries describing all genres associated with the movie.\n",
        "* **homepage**: The movie's official homepage.\n",
        "* **id**: An identifier for the movie.\n",
        "* **imdb_id**: IMDB's identifier for the movie.\n",
        "* **original_language**: The language in which the movie was shot.\n",
        "* **original_title**: The original title of the movie.\n",
        "* **overview**: A brief text about the movie.\n",
        "* **popularity**: A Popularity Score given by TMDb.\n",
        "* **poster_path**: The URL of the poster image.\n",
        "* **production_companies**: A stringified list of production companies involved with making of the movie.\n",
        "* **production_countries**: A stringified list of countries in which the movie was produced.\n",
        "* **release_date**: Release date of the movie in theaters.\n",
        "* **revenue**: The total revenue of the movie in dollars.\n",
        "* **runtime**: The runtime of the movie in minutes.\n",
        "* **spoken_languages**: A stringified list of languages spoken in the film.\n",
        "* **status**: The status of the movie (Released, To Be Released, etc.)\n",
        "* **tagline**: The movie's tagline.\n",
        "* **title**: The official title of the movie.\n",
        "* **video**: Indicates whether there is a video of the movie in TMDb.\n",
        "* **vote_average**: The average rating of the movie, on a 0-10 scale.\n",
        "* **vote_count**: The number of votes by users, as counted by TMDb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6b418588e3f9139f74cb3a9546f5dca49729579b",
        "id": "2Clue5Z_Cgbc"
      },
      "source": [
        "# Imports\n",
        "\n",
        "First, let's make sure to import Pandas and NumPy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0K3Aw3eAf2B"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFlHk-e0BZME"
      },
      "source": [
        "# Exercise 1: Loading, preprocessing and cleaning the data (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGJnqtQD1BOs"
      },
      "source": [
        "Read the movie dataset from the following URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQb46KRIAkOB"
      },
      "source": [
        "url = 'http://courses.compute.dtu.dk/02807/2020/projects/project1/movies_metadata.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQrm5PleClKz"
      },
      "source": [
        "## Part 1: Reading and preprocessing the data (10 pts)\n",
        "\n",
        "Sometimes, raw data read from a file will be treated by default as string data. For example, the `genres` field in our dataset would be loaded by default as a stringified list of dictionaries. \n",
        "\n",
        "If we load this data as a string, we won't be able to access it conveniently. Some preprocessing step is therefore needed.\n",
        "\n",
        "Write a function `load_movies_data()` that reads the URL into a Pandas DataFrame and preprocesses its columns to ensure that:\n",
        "\n",
        "1. Data in the `release_date` field consists of Pandas `Timestamp` objects, except for missing values. For example, executing a code cell with `df.release_date[0]` should display the output `Timestamp('1995-10-30 00:00:00')`.\n",
        "\n",
        "2. Data in the `belongs_to_collection` consists of Python dictionaries.\n",
        "\n",
        "3. Data in the `genres`, `production_companies` and `production_countries` fields should consist of lists of Python dictionaries. \n",
        "\n",
        "For example, executing a code cell with `df.genres[0]` should display the output \n",
        "```\n",
        "[{'id': 16, 'name': 'Animation'},\n",
        " {'id': 35, 'name': 'Comedy'},\n",
        " {'id': 10751, 'name': 'Family'}]\n",
        "```\n",
        "Note that that is a list object, not a string. The elements of the list are dictionaries (executing `df.genres[0][0]['name']` returns `'Animation'`). \n",
        "\n",
        "*Hint*: for items 2 and 3, you could use `ast.literal_eval`.\n",
        "\n",
        "Do not loop explicitly over the rows of the DataFrame to perform these preprocessing steps. These format conversions can be performed more efficiently using Pandas' in-built functions and/or calling Pandas' `apply()`with appropriate arguments. You'll be asked below to time the loading and preprocessing step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mC5hjGXJTZ0"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZvSPPdzfScL"
      },
      "source": [
        "Now call `load_movies_data()` and load the data into a DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-eOSqlhD-8J"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnelY1bZzj-J"
      },
      "source": [
        "Display the DataFrame. You should check that it looks correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP6zpeLxu4J-"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuzjOV7ffbpR"
      },
      "source": [
        "## Part 2: Timing your function (2.5 pts)\n",
        "\n",
        "Time the performance of your function. To get the points for this part, the time reported below must not exceed 60 seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIYWL17bO2Ih"
      },
      "source": [
        "load_time = %timeit -o -r 3 load_movies_data(url)\n",
        "print(\"Time (s):\", load_time.best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sVQeTkLYI2b"
      },
      "source": [
        "## Part 3: Cleaning the data (2.5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ydbZ-KFYlRX"
      },
      "source": [
        "Filter/drop all rows meeting any of these conditions:\n",
        "* The `adult` value is not `'False'`\n",
        "* The `vote_count` value is missing\n",
        "* The `vote_average` value is missing\n",
        "\n",
        "Do not loop over rows to perform these checks. Use Pandas' in-built functionality to do so. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtb7AaaVY5nm"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT8jdILukiBF"
      },
      "source": [
        "# Exercise 2: Computing IMDb's ratings (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84SE_eMzkyC1"
      },
      "source": [
        "The Top Rated 250 titles in IMDb are calculated using [a formula](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#calculatetop) that takes into account the number of votes that a title has received, the minimum votes required to be on the list, and the mean vote for all titles. The rating for a title is given as follows:\n",
        "\n",
        "$$ \\text{weighted rating } = \\left(\\frac{v}{v+m} \\cdot R\\right) + \\left(\\frac{m}{v+m} \\cdot C\\right)$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$m$ = the minimum number of votes required to be listed in the Top Rated ranking. We'll let $m=1000$.\n",
        "\n",
        "$v$ = the number of votes received by the title (the title's **`vote_count`** value)\n",
        "\n",
        "$R$ = the average rating for the title (the title's **`vote_average`** value)\n",
        "\n",
        "$C$ = the mean vote across the whole list (the mean over the **`vote_average`** column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85J4HDO2rieA"
      },
      "source": [
        "We are going to compute the ratings for movies that could be listed in IMDb's Top Rated 250 ranking.  We want to do this as efficiently as possible. As a baseline for benchmarking, we'll use a non-optimised solution that simply loops over the rows of the dataset and computes the weighted rating for the corresponding movie, if the movie has more than 1000 votes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyYhLdBksTec"
      },
      "source": [
        "C = df['vote_average'].mean()\n",
        "m = 1000\n",
        "\n",
        "def weighted_rating(row):\n",
        "  if row['vote_count'] > m:\n",
        "    v = row['vote_count']\n",
        "    R = row['vote_average']\n",
        "    return (v/(v+m) * R) + (m/(v+m) * C)\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "def weighted_rating_loop(df):\n",
        "  rating_list = []\n",
        "  for i in range(0, len(df)):\n",
        "    rating = weighted_rating(df.iloc[i])\n",
        "    rating_list.append(rating)\n",
        "  df['imdb_rating'] = rating_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIsei1w4r9Jz"
      },
      "source": [
        "weighted_rating_loop(df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdlffrsJyHvI"
      },
      "source": [
        "Let's look at the average performance of this function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su__dMpZyX5W"
      },
      "source": [
        "basic_time = %timeit -r 3 -o weighted_rating_loop(df)\n",
        "print(\"Best time:\", basic_time.best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPjyKJ2zzPoQ"
      },
      "source": [
        "In the remaining parts of the exercise, you are going to be asked to come up with alternative ways to compute the ratings, using various methodologies. Let's create a score board to keep track of performance. Here's a description of the rows:\n",
        "\n",
        "*   **Best single run time (s)**:  The best time used by your solution, in seconds.\n",
        "*   **Marginal performance improvement**: The time improvement of your current solution over its immediately preceding solution. Given by: $\\frac{\\text{best single run time (s) of previous solution}}{\\text{best single run time (s) of current solution}}$\n",
        "*   **Performance improvement over basic looping**:  The time improvement over our baseline solution. Given by: $\\frac{\\text{best single run time (s) of weighted_rating_loop}}{\\text{best single run time (s) of current solution}}$\n",
        "*   **Best single run time (s, teacher)**: The time of a solution provided by the teacher. \n",
        "*   **Marginal performance improvement (teacher)**: The time improvement of the teacher's solution over its immediately preceding solution. \n",
        "*   **Performance improvement over basic looping (teacher)**:  The teacher's solution improvement over the baseline solution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV-xfrs53NBF"
      },
      "source": [
        "timing_data = {\n",
        "        'Best single run time (s)': [basic_time.best,np.nan, np.nan, np.nan,np.nan],\n",
        "        'Marginal performance improvement': [np.nan,np.nan, np.nan, np.nan,np.nan],\n",
        "        'Performance improvement over basic looping': np.nan,\n",
        "        'Best single run time (s, teacher)': [12.1,6.13, 0.940, 0.0079,0.00113],\n",
        "        'Marginal performance improvement (teacher)': [np.nan,'x2.01', 'x6.15', 'x89.4', 'x6.1'],\n",
        "        'Performance improvement over basic looping (teacher)': [np.nan,'x1.87', 'x12.87', 'x1531','x9307']}\n",
        "\n",
        "timings = pd.DataFrame(timing_data,index=[\"Basic looping\", \"Iterrows looping\", \"Apply()\", \"Pandas vectorisation\", \"NumPy vectorisation\"])\n",
        "timings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfD0eUlHgz3l"
      },
      "source": [
        "**The grading for the following parts works as follows.**\n",
        "\n",
        "Let $m$ be the marginal performance improvement for the teacher's solution over basic looping, and let $m'$ be the marginal performance improvement for your solution over `basic_time`. If a part gives $n$ points, then you will get the $n$ points if $m' \\geq 0.5 m$, and 0 points otherwise.\n",
        "\n",
        "You don't get extra points for performing faster than the teacher's solution. But this is of course possible and you should feel free to optimise away as much as you want!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkiLI2QT7oNY"
      },
      "source": [
        "## Part 1: Less bad looping with `iterrows` (2.5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmZIqPIf743q"
      },
      "source": [
        "Define a function `weighted_rating_iterrows(df)` that computes the ratings by looping over rows with the in-built iterator `iterrows`, and stores the results in a new column of the DataFrame called called `imdb_rating_iter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4dTxRfW6Gc4"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsvOtN6y8Ycg"
      },
      "source": [
        "Call the function and make sure that it works as intended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLKzzVP86bza"
      },
      "source": [
        "weighted_rating_iterrows(df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC-m0iR48jM6"
      },
      "source": [
        "Time the performance of the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y3BWusJ8y70"
      },
      "source": [
        "iterrows_time = %timeit -r 3 -o weighted_rating_iterrows(df)\n",
        "print(\"Best time:\", iterrows_time.best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HexMOOCB82e_"
      },
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SQRS_gdJCbM"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-FhuhB99em4"
      },
      "source": [
        "## Part 2: Using `apply()`. (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ294FYn9qhO"
      },
      "source": [
        "Define a function `weighted_rating_apply(df)` that computes the ratings using Pandas' `apply()` function, and stores the results in a new column of the DataFrame called `'imdb_rating_apply`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk3SdbQs8ghG"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBgP1e1uCMlF"
      },
      "source": [
        "Call the function and make sure that it works as intended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUaYXC_RCMlK"
      },
      "source": [
        "weighted_rating_apply(df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9jjZI14CMlO"
      },
      "source": [
        "Time the performance of the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqggBfTMCMlP"
      },
      "source": [
        "apply_time = %timeit -r 3 -o weighted_rating_apply(df)\n",
        "print(\"Best time:\", apply_time.best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DzMnzf4CMlS"
      },
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4RSuVOYV0JZ"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4465hgrHlth8"
      },
      "source": [
        "## Part 3: Understanding vectorisation (2.5 pts)\n",
        "\n",
        "Explain briefly what vectorisation is and why vectorised operations in Python can be orders of magnitude faster than non-vectorised operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKVE22l0JU7y"
      },
      "source": [
        "*your answer goes here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZHPgFMsED_6"
      },
      "source": [
        "## Part 4: Vectorised solution with Pandas (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI7zQxGNGZnX"
      },
      "source": [
        "Let's find a vectorised solution using Pandas. You have to define a function `weighted_rating_pandas(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imbd_ratings_pandas`. Use Pandas operations only: don't transform your data into NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqIXsMGFGZnY"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKVGubslGZna"
      },
      "source": [
        "Call the function and make sure it works as intended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXf4KAj1GZna"
      },
      "source": [
        "weighted_rating_pandas(df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scNFR7X8GZnc"
      },
      "source": [
        "Time the performance of the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbhwZZ0mGZnf"
      },
      "source": [
        "pandas_time = %timeit -r 3 -o weighted_rating_pandas(df)\n",
        "print(\"Best time:\", pandas_time.best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsqz0kUJGZnh"
      },
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxCI0nUXV3Lk"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwaE7pIjzEa"
      },
      "source": [
        "Time to reflect on your solution. Do the following: \n",
        " \n",
        "* Explain in words what your function does and why it is a vectorised solution. **If you don't explain how the function works, or your explanation has major errors, we will substract points for this part.**\n",
        " \n",
        "* Display a profiler and give an analysis of what you see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQHB_JqeV52E"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DngbQA2eV770"
      },
      "source": [
        "*Your explanation goes here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLwJEzATEKwi"
      },
      "source": [
        "## Part 5: Vectorised solution with NumPy (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrAZ4OI2EPk8"
      },
      "source": [
        "Let's find a vectorised solution that uses NumPy to speed up the calculations. You have to define a function `weighted_rating_numpy(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imbd_ratings_numpy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sJlkDYAzQr8"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pAc_GEEudy"
      },
      "source": [
        "Call the function and make sure it works as intended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IALbcsKO2RNt"
      },
      "source": [
        "weighted_rating_numpy(df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0ebRPwiFAfo"
      },
      "source": [
        "Time the best performance of the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWe52oAQ6l8R"
      },
      "source": [
        "numpy_time = %timeit -r 3 -o weighted_rating_numpy(df)\n",
        "print(\"Best time:\", numpy_time.best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB7tkhUDFAfr"
      },
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8MBiqnvushL"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtPAX91IlGM0"
      },
      "source": [
        "Time to reflect on your solution. Do the following: \n",
        " \n",
        "* Explain in words what your function does and why it is vectorised solution. **If you don't explain how the function works, or your explanation has major errors, we will substract points for this part.**\n",
        " \n",
        "* Display a profiler and give an analysis of what you see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV8aYhv5WEqA"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7lgegwDWFTt"
      },
      "source": [
        "*Your explanation goes here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcGeZKuIRHe7"
      },
      "source": [
        "## Part 6: Find out the top 25 titles (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-IE_GfsRMOG"
      },
      "source": [
        "What are the top 25 titles? Now that we have the IMDb ratings conveniently stored in a column, display the top 25 titles, together with their IMDb rating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svC-x1ZcRNJ4"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ca4XaEtqvwt"
      },
      "source": [
        "# Exercise 3: Predicting the genre of movies (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irkcmAfTHTzR"
      },
      "source": [
        "In this exercise, you'll be asked to create a number of features and use them to predict whether a movie is a science fiction movie or not. \n",
        "For this classification task, we'll work with a different part of the movies dataset, which contains more information for each movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs0dJMEG1PLL"
      },
      "source": [
        "train_url = 'http://courses.compute.dtu.dk/02807/2020/projects/project1/train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIcpNS2GCXUi"
      },
      "source": [
        "You'll try to predict whether a movie is a science fiction movie based on the other associated genres for the movie, the people and companies involved in making it, as well as its release date."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkN5bCjoCPW9"
      },
      "source": [
        "## Part 1: Adding binary features for genres (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA00jck22BKq"
      },
      "source": [
        "As in Exercise 1, the data on several columns is in a stringified format. Pre-process the following columns appropriately, as you did with the `genres` column in Part 1 of Exercise 1.\n",
        "```\n",
        "'belongs_to_collection', 'genres', 'production_companies','production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew'\n",
        "```\n",
        " \n",
        "Don't loop explicitly over the rows to perform this preprocessing. Use `apply()` or some form of vectorisation. Your dataframe should be named `train`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHi0Ejxb2bKM"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z57lsGZ5IL7b"
      },
      "source": [
        "Looking at the 'genres' column, you can see that movies have a varying number of associated genres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amzV_VzSE0VL"
      },
      "source": [
        "# this will work only if you've already preprocessed the genres' column into lists of dicts\n",
        "for i, v in enumerate(train.genres.head()):\n",
        "    print(i, v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPDjPDHlInOC"
      },
      "source": [
        "Count the number of movies that have $n$ associated genres, for each $n$ in the dataset. If a movie has no associated genres, assign it the number 0. \n",
        "\n",
        "You have to use Pandas in-built functions only (no explicit looping). For example, you could use `apply()` with an appropriate function to apply to each row. \n",
        "\n",
        "Once you have the counts, visualise them as a bar chart, with one bar per possible number of associated genres, and the height of the bar representing the number of movies with that number of genres.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cHqZJ8iImh1"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqA9UQ3rJyBQ"
      },
      "source": [
        "Let's create our binary features next. Complete the following taks:\n",
        " \n",
        " \n",
        "1.   Find the the 20 most common genres. \n",
        "2.   Transform the `genres` column by replacing its current entries with the list of names of genres occurring in the entries.  For example, the entry \n",
        "```\n",
        "[{'id': 10749, 'name': 'Romance'}, {'id': 35, 'name': 'Comedy'}]\n",
        "```\n",
        "should be transformed into:\n",
        "```\n",
        "['Romance','Comedy']\n",
        "```\n",
        "Empty entries should be transformed into the empty list `[]`.\n",
        "3. Create a separate column for each of the 20 most common genres, with name `genre_(nameofgenre) (e.g. `genre_Comedy`). A movie should have a 1 on a genre's column if the genre is one of the associated genres for that movie, and a 0 otherwise.\n",
        " \n",
        "Don't iterate explicitly over the rows to perform these operations. Use in-built functions, such as `apply()`, or vectorisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVXMvDv3Mk1t"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN65zGfLnSe-"
      },
      "source": [
        "Visualise the number of movies per top 20 genre with a chart of your choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEjJJkMZh9mF"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M79tzVdMDfXL"
      },
      "source": [
        "## Part 2: adding binary features for companies, crew and actors (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iZngZ3ZnAsG"
      },
      "source": [
        "You've now extracted binary features for all genres associated with a movie. When trying to predict whether a movie is a science fiction movie or not, knowing what other genres it is associated with may be useful. But there's other information that we could use to base our predictions. \n",
        "\n",
        "The `genres` column is just one out of several columns containing lists of dictionaries as entries. For example, the `production_companies` column also contains lists of dictionaries, providing names of the companies producing the movie. As you just did with genres, add new columns for:\n",
        " \n",
        "1.   The names of the 30 most common production companies\n",
        "2.   The names of the 30 most common production countries\n",
        "3.   The names of the 30 most common actors (`cast` column) \n",
        "4.   The names of the 30 most common crew members\n",
        "5.   The names of the 30 most common keywords\n",
        " \n",
        "Don't iterate explicitly over to create these columns. Use `apply()` or vectorisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sO8Tsqduatn"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjFFSEJs93yJ"
      },
      "source": [
        "Check the result. You should now have a much wider table, with the new columns consisting of binary features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyORi5V27Mg0"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joEcHikdD5SY"
      },
      "source": [
        " ## Part 3: adding numerical date features (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nliC-9woDYd_"
      },
      "source": [
        "Next, we'll create some features based on the release date information. Create a new column storing the value for each of the following  aspects of a release date:\n",
        " \n",
        "```\n",
        "[\"year\", \"weekday\", \"month\", 'weekofyear', 'day', 'quarter']\n",
        "```\n",
        " \n",
        "As usual, you should use `apply()` or vectorisation to create these columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K5u197bDX1A"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWLi9-BW97VX"
      },
      "source": [
        "Next, we'll drop the columns that will not be used for learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbycSRqu8dR5"
      },
      "source": [
        "train = train.drop(['id','homepage', 'original_language','title', 'imdb_id','crew', 'poster_path', 'release_date', 'status','belongs_to_collection','Keywords','original_title','overview','production_companies','production_countries', 'spoken_languages', 'tagline', 'cast','genres'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOlV7ho4-OR9"
      },
      "source": [
        "Lastly, drop any rows with missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asrzvNYy-NO4"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV_ANmOH0rQJ"
      },
      "source": [
        "## Part 4: Prediction (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y1XUwNX0rQL"
      },
      "source": [
        "Let's load the necessary `sklearn` libraries and prepare the training data for learning. Recall that your goal is to predict whether a movie has science fiction as an associated genre. So you're dealing with a binary classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qpz2Cd60rQM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWzqddf90rQR"
      },
      "source": [
        "Use `sklearn` to prepare the training and test sets, setting aside 15% of the data for testing. Call the training input features, training labels, test input features and test labels as follows:\n",
        "\n",
        "```\n",
        "x_train, x_test, y_train, y_test\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDLDQWPl0rQS"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKaGZrSuLg1K"
      },
      "source": [
        "Feature scaling is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). Run the following code to feature scale your input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by0c0S7s0rQY"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(x_train)  \n",
        "x_train = scaler.transform(x_train) \n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxX0ugDuNR8o"
      },
      "source": [
        "Check that the shape of your data looks correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tJHqw2M0rQf"
      },
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90SIHxqzN3Ht"
      },
      "source": [
        "Train a classifier of your choice. Then print the accuracy and confusion matrix over the validation set. You should be able to get around 90% accuracy, although the number of false negatives is likely to be quite high."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIg8WIm3NiKN"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc4EOB-gb5pp"
      },
      "source": [
        "# Exercise 4: Basic movie recommendation system (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PqirpLgVdN0"
      },
      "source": [
        "In this exercise, you'll build a simple movie recommendation system.  The system will take a movie as input and recommend a list of similar movies. In order to recommend similar movies, you will use the correlation between the ratings of movies as a similarity metric. We'll use Pearson's correlation. \n",
        " \n",
        "The data for this exercise is available in the following URLs. It contains basic info about movies, as well as ratings provided by several users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOHERjo8cLQo"
      },
      "source": [
        "url1 = 'http://courses.compute.dtu.dk/02807/2020/projects/project1/ratings.csv'\n",
        "url2 = 'http://courses.compute.dtu.dk/02807/2020/projects/project1/movies.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOXKd22xXgo2"
      },
      "source": [
        "## Part 1: Preparing the ratings data (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isn8M65HXi3i"
      },
      "source": [
        "Read the data from these two URLs, and create a single dataframe from them, with the following columns:\n",
        "\n",
        "| userId | movieId | rating | timestamp | title | genres |\n",
        "|--------|---------|--------|-----------|-------|--------|\n",
        "|        |         |        |           |       |        |\n",
        "\n",
        "Call the dataframe `movie_data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwhdEsGUn1zz"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFGc9VSzadHi"
      },
      "source": [
        "To find the correlation between the ratings of movies, create a dataframe where each column is a movie name and each row contains the rating assigned by a specific user to that movie. \n",
        "\n",
        "You'll notice that this dataframe has many NaN values, since each movie is not rated by every user. Call the dataframe `user_ratings`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTrrVPsrfn1Q"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy61Luqyu2Te"
      },
      "source": [
        "## Part 2: Finding the most similar movies (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7FBDshDd1j7"
      },
      "source": [
        "Each column contains all the user ratings for a particular movie. Let's take the user ratings for the movie Toy Story."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e-9WXAro_4-"
      },
      "source": [
        "toystory_ratings = user_ratings['Toy Story (1995)']\n",
        "toystory_ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fljIQkJmpCJD"
      },
      "source": [
        "Next, find the correlation between the user ratings for Toy Story and the user ratings of all other movies. \n",
        " \n",
        "More specifically, create a dataframe that contains two columns, called `title` and `Correlation`. Each row should contain a movie title $x$, followed by the pairwise correlation between the column of ratings for Toy Story and the column of ratings for $x$.  Drop any rows with null values, and display the resulting dataframe.\n",
        " \n",
        "Use in-built functions to compute correlations and avoid explicit loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yuX1U0Xh0nk"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aji7cUw-r-JG"
      },
      "source": [
        "Sort the movies by descending order of correlation to find out highly correlated movies at the top. Display the 5 most highly correlated movies.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU0Zm9fjg4BD"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrvD_u63sVdD"
      },
      "source": [
        "If you computed correlations correctly, you will find that the recommended movies are not very well known. We can generate more popular recommendations by finding highly correlated movies that have a sensible number of ratings. \n",
        " \n",
        "Add a column to your correlation table, called `rating_counts`, which stores the number of ratings received by each movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvMKUmBFg-Ow"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_20nfFvt-7y"
      },
      "source": [
        "Now find the 5 movies with the highest correlation with Toy Story, which have strictly more than 100 ratings. Display the result below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvE3c2lMhHNz"
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}