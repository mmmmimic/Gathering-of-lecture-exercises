{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercises_week_8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlMcbNUbMqnF"
      },
      "source": [
        "# 02807 - Week 8 Exercises:  Getting started with Spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asspwlX7zDcT"
      },
      "source": [
        "# Learning objectives:\n",
        "\n",
        "* Getting hands-on experience manipulating DataFrames with built-in Spark functions\n",
        "* Distinguishing actions and transformations\n",
        "* Writing your own UDFs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsEltdQrKqcI"
      },
      "source": [
        "# Readings:\n",
        "\n",
        "\n",
        "* [*Learning Spark*, Chapters 1-3](https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf). A nicely structured and detailed introduction to Spark.\n",
        "* [A Neanderthalâ€™s Guide to Apache Spark in Python](https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427). A brief, fun and gentle introduction to Spark for complete beginners.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3D6xQ8JHpU6"
      },
      "source": [
        "# Setup\n",
        "\n",
        "You'll need to get pyspark and make some imports. The following cells will get you started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeB1RqD6Epce"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhJLQ3doEzrx"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ectQxRreAvJ"
      },
      "source": [
        "# Exercise 1: age bracketing for the Titanic Dataset\n",
        "\n",
        "In this exercise you should use Spark to count the number of Titanic passengers in different age brackets. More specifically, you need to count the number of people age 0 to 9, 10 to 19, and so on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r1CJbUdeygx"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "Load the Titanic data used in the lecture slides into a Spark dataframe (use schema inference)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my6Awbl-e4AO"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSZvg7eOe7ok"
      },
      "source": [
        "## Cleaning the data\n",
        "\n",
        "Remove the rows that do not have an age \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJrRTjQLfTsq"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jzO0ggSfAFs"
      },
      "source": [
        "## Adding age brackets \n",
        "\n",
        "Create a new column with a value that identifies the bracket that passengers are in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2bOTGcpfIES"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCLsqtqVfKwb"
      },
      "source": [
        "## Age bracket counts\n",
        "\n",
        "Create a Spark dataframe with the sum of passengers in each bracket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm9fldBlfVmK"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvB1CeqSfYXP"
      },
      "source": [
        "# Exercise 2: understanding actions and transformations\n",
        "\n",
        "For each of the following Spark operations, decide if they are transformations or actions. If they are transformations, determine if they are wide or narrow.\n",
        "\n",
        "* ``select()``\n",
        "* `groupBy()`\n",
        "* `filter()`\n",
        "* `where()`\n",
        "* `count()`\n",
        "* `show()`\n",
        "* `agg()`\n",
        "* `write()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MQ2mtJLfu5_"
      },
      "source": [
        "*Your answers go here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wztxj5t_6m-h"
      },
      "source": [
        "# Exercise 3: exploratory data analysis for the Chicago crime dataset\n",
        "\n",
        "\n",
        "The Chicago Crime dataset contains a summary of the reported crimes occurred in the City of Chicago from 2001 to 2017. \n",
        "\n",
        "It is a fairly large dataset. You'll work with a sample of it. Execute the following cells to load it into a dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI_uHpru67uN"
      },
      "source": [
        "# to get the full dataset, run: !wget https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD\n",
        "!wget https://ibm.box.com/shared/static/svflyugsr9zbqy5bmowgswqemfpm1x7f.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF3lGIMr-1ku",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "!ls -1\n",
        "!mv rows.csv\\?accessType\\=DOWNLOAD reported-crimes.csv\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfnqE8Jx_Eve"
      },
      "source": [
        "rc = spark.read.csv('reported-crimes.csv',header=True)\n",
        "rc.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxVWqtnaILqj"
      },
      "source": [
        "Let's do some EDA. Answer the following questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DknyPxfkFFVz"
      },
      "source": [
        "**What percentage of reported crimes resulted in an arrest?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9S4hZanFPCf"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uToZfa01Fqi9"
      },
      "source": [
        "**What are the top 3 locations for reported crimes?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3bxfL6wFvjJ"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI6uPOV7GCAH"
      },
      "source": [
        "**What is the most common primary type of crime in district 022?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojh8eHFUGNG9"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}